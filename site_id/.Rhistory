# Read in gages site dat
gages <- read_csv("gagesII_2011_conterm_all.csv",
col_types = cols(STAID = col_character()))
library(dataRetrieval)
library(readr)
# Read in gages site dat
gages <- read_csv("gagesII_2011_conterm_all.csv",
col_types = cols(STAID = col_character()))
View(gages)
# Extract Gages sites
gages_sites <- as.character(gages$STAID)
# Create dataframe to store site numbers and start and end date for stream temperatures
site.df <-  data.frame(site = gages_sites, begin_date = rep(as.Date(0,origin="1970-01-01"),length(gages_sites)),
end_date = rep(as.Date(0,origin="1970-01-01"),length(gages_sites)), n_days = rep(0,length(gages_sites)))
# Loop through GAGESII sites
for (i in seq(1,length(gages_sites))){
# Retrieve what NWIS data is available from site i
# Catch errors caused by site missing from USGS NWIS
dailyData <- tryCatch(whatNWISdata(siteNumber = gages_sites[i],service="dv", statCd="00003"),error = function(e) e)
# If no error occurs, run through normal code
if (class(dailyData) == "data.frame") {
# Check if stream temperature data (parm_cd = '00010') exists
# If x = 1, data exists
# If x = 0, data does not exist
x <- length(which(dailyData$parm_cd == "00010"))
# Stream temperature data exists
if (x == 1) {
# Extract data from row containing stream temperature data
site.df$begin_date[i] <- as.Date(dailyData[which(dailyData$parm_cd == "00010"),]$begin_date,format="Y-%m-%d")
site.df$end_date[i] <- as.Date(dailyData[which(dailyData$parm_cd == "00010"),]$end_date,format="Y-%m-%d")
site.df$n_days[i] <- dailyData[which(dailyData$parm_cd == "00010"),]$count_nu
} else { # Stream temperature data doesn't exist
site.df$begin_date[i] <- NA
site.df$end_date[i] <- NA
site.df$n_days[i] <- NA
}
} else { # If error occurs, set row to NA
site.df$begin_date[i] <- NA
site.df$end_date[i] <- NA
site.df$n_days[i] <- NA
}
}
View(site.df)
# Filter sites with temperature data
temp_sites <- site.df[which(is.na(site.df$begin_date) == FALSE),]
View(temp_sites)
# Write sites with temperature data to csv
write.csv('temp_sites.csv')
# Write sites with temperature data to csv
write.csv(temp_sites,'temp_sites.csv')
# Create dataframe for identifying years with the most complete data
tempmat <- matrix(nrow=1468,ncol=37)
date4yr.df <- cbind(temp_sites,tempmat)
# Create dataframe for identifying years with the most complete data
tempmat <- matrix(nrow=dim(temp_sites)[2],ncol=37)
# Create dataframe for identifying years with the most complete data
tempmat <- matrix(nrow=dim(temp_sites)[1],ncol=37)
date4yr.df <- cbind(temp_sites,tempmat)
names(date4yr.df)[5:41] <- paste("Y",seq(1980,2016),"-",seq(1984,2020),sep="")
View(date4yr.df)
# Create list of intervals for start and end dates of years 1980-2020
int.list4yr <- list()
for (i in seq(1980,2016)){
# Define start and end dates
d1 <- as.Date(paste(i,"-01-01",sep=""),format="%Y-%m-%d")
d2 <- as.Date(paste((i+4),"-01-01",sep=""),format="%Y-%m-%d")
# Add interval to lsit
int.list4yr[[(i-1979)]] <- interval(d1,d2)
}
View(int.list4yr)
for (i in seq(1980,2016)){
# Define start and end dates
d1 <- as.Date(paste(i,"-01-01",sep=""),format="%Y-%m-%d")
d2 <- as.Date(paste((i+4),"-01-01",sep=""),format="%Y-%m-%d")
# Add interval to lsit
int.list4yr[[(i-1979)]] <- interval(d1,d2)
}
library(lubridate)
for (i in seq(1980,2016)){
# Define start and end dates
d1 <- as.Date(paste(i,"-01-01",sep=""),format="%Y-%m-%d")
d2 <- as.Date(paste((i+4),"-01-01",sep=""),format="%Y-%m-%d")
# Add interval to lsit
int.list4yr[[(i-1979)]] <- interval(d1,d2)
}
View(int.list4yr)
# Loop through sites to identify years with most data
for (i in seq(1, length(temp_sites$site))){
# Define start and end date interval
int <- interval(date4yr.df$begin_date[i], date4yr.df$end_date[i])
# Loop through interval list
for (j in seq(1,length(int.list4yr))){
# Check if interval is within each year's interval
if (int.list4yr[[j]] %within% int == TRUE) {
date4yr.df[i,(j+4)] <- 1 # Set year column to 1 if date is contained in range
} else {
date4yr.df[i,(j+4)] <- 0 # Set year column to 0 if date is contained in range
}
}
}
View(date4yr.df)
data_4yr <- colSums(date4yr.df[,c(5:41)])
data_4yr
# Pull out sites with data from 2016-2020
sites_16.20 <- date4yr.df[which(date4yr.df$`Y2016-2020` == 1),c(1:4)]
View(sites_16.20)
# Add apostrophe to site numbers to preserve leading 0 in Excel
sites_16.20$site <- paste("'",sites_16.20$site,sep="")
View(sites_16.20)
# Write sites to csv
write.csv(sites_16.20, "AllSites_with_2016_2020_data.csv",row.names=FALSE)
__DIR__
install.packages("rstudioapi")
library(rstudioapi)
library(rstudioapi)
dirname(getActiveDocumentContext()$path)
getActiveDocumentContext()
setwd("E:/Users/Jeff/Github/stream-temperature-rf/site_id")
getActiveDocumentContext()
dirname(getActiveDocumentContext()$path)
setwd(dirname(getActiveDocumentContext()$path))
rstudioapi::getActiveDocumentContext()$path
source("GAGES_StreamTemp_Sites.R", chdir = TRUE)
parent.frame(2)$ofile
dirname(rstudioapi::getActiveDocumentContext()$path)
